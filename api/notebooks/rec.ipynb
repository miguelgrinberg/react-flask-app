{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed05239c",
   "metadata": {},
   "source": [
    "# Movie Recommendation Algorithm\n",
    "\n",
    "As part of this task, you are expected follow the instructions below and create a movie recommendation algorithm to make your users happy :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9275f19",
   "metadata": {},
   "source": [
    "### 1. We start off with the known dependencies we need\n",
    "\n",
    "Pandas is a must. Pandas is a powerful data analysis library built for Python users. It helps us manipulate complicated data in a user-friendly manner. You will understand soon the convenience of it and come to love it as much as we do. \n",
    "\n",
    "Please use the run button on the right hand side to execute the code block below. Once the dependencies are imported successfully, you will see a green tick at the bottom of the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd890892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # refer to pandas as pd\n",
    "from movie_details import get_movies_by_id  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cae9c846",
   "metadata": {},
   "source": [
    "### 2. Then we need to get our movies dataset\n",
    "\n",
    "The dataset includes thousands of movies and detailed information for each one of them. Let's see how it looks like shall we? \n",
    "\n",
    "Run the code block below to execute the code. Once the code block runs, the dataset will be displayed underneath the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6234625",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/dataset2.csv\"\n",
    "df = pd.read_csv(path) # df stands for Data Frame\n",
    "df.head(10) # display the first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38342e06",
   "metadata": {},
   "source": [
    "As you can see, the dataset doesn't look very pretty, does it? That's why we need Pandas to get exactly what we need from the dataset. We need the following three columns from the dataset:\n",
    "* title\n",
    "* imdbID\n",
    "* overview\n",
    "\n",
    "Try running the code block below to see how to get your desired columns from a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbad43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['title', 'imdb_id', 'overview']]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78acd667",
   "metadata": {},
   "source": [
    "Let's create a function that returns the **title**, **imdbID** and **overview** of all the movies in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    path = \"./data/dataset2.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['title', 'imdb_id', 'overview']]\n",
    "    df['overview'] = df['overview'].fillna('') # replace NaN values with an empty string\n",
    "    return df\n",
    "\n",
    "df = get_dataset() # call the function and save it as a Dataframe\n",
    "df.head(5) # Display the first 5 entries of the Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac86fc0a",
   "metadata": {},
   "source": [
    "### 3. It's time to deliver our user's request\n",
    "\n",
    "Our users have requested a feature where when they add a new movie to their favourites, they would like to get 2 new movie recommendations. The UI has already been prepared for this task. All there is left to do is:\n",
    "* Get the movie details of the favourited movie from OMDB API using the IMDB ID of the movie\n",
    "* Add the details to our dataset \n",
    "* If it already exists in the dataset, remove duplicates\n",
    "\n",
    "#### 3.1 Get the details of the favourited movie\n",
    "\n",
    "Luckily, another teammate has already created a function called 'get_movies_by_id' to get the movie details by IMDB ID. Run the code block below and test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_movies_by_id(\"tt0029927\") # get movie details with IMDB ID\n",
    "# response = pd.json_normalize(response) # uncomment to normalize response from OMDB API into a flat Data Frame\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d81d55",
   "metadata": {},
   "source": [
    "So it works! But as you can see the column names do not match the ones that the dataset has for the same information... This sort of mismatch happens often when we use different data sources.\n",
    "\n",
    "| column info | column name in dataset | column name in API response |\n",
    "| --- | --- | --- |\n",
    "|Title |title|Title|\n",
    "|IMDB ID|imdb_id| imdbID|\n",
    "|Overview | overview| Plot |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2dec62",
   "metadata": {},
   "source": [
    "##### 3.2 Let's create a function that adds the neccessary details of the favourited movie to the dataset\n",
    "\n",
    "Important points to consider:\n",
    "* Function should take an IMDB ID as an input\n",
    "* The column names should match\n",
    "* There shouldn't be any duplicates in the dataset\n",
    "* Function should return the updated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f233e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4bd28",
   "metadata": {},
   "source": [
    "### 4. Create the recommendation algorithm\n",
    "\n",
    "We will be focusing on the plot of the movies and use NLP (Natural Language Processing) to find similarities between the plot of the favourited movie and all the other movie plots in our database.\n",
    "\n",
    "First, we need to import the necessary Python machine learning libraries that we can use to complete the task. \n",
    "\n",
    "Scikit-learn (full name for sklearn) is a machine learning library for Python programming. It includes simple and efficient tools for predictive data analysis. [Check here for more](https://scikit-learn.org/stable/index.html).\n",
    "\n",
    "We will use one of it's functionalities that allows us to perform data analysis on text. We will compute pairwise similarity scores for all movies based on their plot descriptions and recommend movies based on that similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db13364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007af98",
   "metadata": {},
   "source": [
    "Now if you are wondering how we will achieve that, one way of doing it is to create a Term Frequency-Inverse Document Frequency (TF-IDF) matrix... \n",
    "\n",
    "In human words, **TF (Term Frequency)** is the relative frequency of a word in a document and is given as (term instances/total instances). \n",
    "\n",
    "**IDF (Inverse Document Frequency)** is the relative count of documents containing the term is given as log(number of documents/documents with term).\n",
    "\n",
    "The overall importance of each word to the documents in which they appear is equal to **TF * IDF**.\n",
    "\n",
    "This will give you a matrix where each column represents a word in the overview vocabulary (all the words that appear in at least one document) and each row represents a movie, as before.This is done to reduce the importance of words that occur frequently in plot overviews and therefore, their significance in computing the final similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bda8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_plot(\"tt0029927\")\n",
    "\n",
    "# Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df['overview'])\n",
    "\n",
    "# Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88351959",
   "metadata": {},
   "source": [
    "We see that over 11,000 different words were used to describe the 1517 movies in our dataset. Now we can go ahead and calculate the cosine similarity score using our matrix and **linear_kernel()** functionality from the Scikit-learn library.\n",
    "\n",
    "One explanation of a kernel is as follows: \n",
    "\n",
    "> a collection of distinct forms of pattern analysis algorithms, using a linear classifier, they solve an existing non-linear problem\n",
    "\n",
    "So we will use a linear kernel to classify movies as similar or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d768dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity scores between all movies in the dataset\n",
    "sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# We create a new Series where the index is the IMDB IDs and the values are the actual indices from the original dataframe\n",
    "indices = pd.Series(df.index, index=df['imdb_id'])\n",
    "\n",
    "# Let's try getting the index of one movie with its IMDB ID\n",
    "idx = indices[\"tt0029927\"]\n",
    "\n",
    "# Get the pairwsie similarity scores of all movies with that movie\n",
    "sim_scores = list(enumerate(sim[idx]))\n",
    "\n",
    "# Sort the movies based on the similarity scores\n",
    "sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the scores of the 2 most similar movies\n",
    "sim_scores = sim_scores[1:3]\n",
    "\n",
    "# Get the movie indices\n",
    "movie_indices = [i[0] for i in sim_scores]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f33987d",
   "metadata": {},
   "source": [
    "#### Final Challenge\n",
    "\n",
    "Create a function that takes an IMDB ID as an input and returns the IMDB IDs of the recommended two movies and display the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88856b01",
   "metadata": {},
   "source": [
    "Now let's move all the functions you created to the recommend.py file. Functions to move:\n",
    "* get_dataset()\n",
    "* add_plot()\n",
    "* get_recommendation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
